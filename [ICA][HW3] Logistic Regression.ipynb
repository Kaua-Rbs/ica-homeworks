{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PARTE 0 | Importes Necessários"
      ],
      "metadata": {
        "id": "V_LLfWXdaM9z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, PowerTransformer"
      ],
      "metadata": {
        "id": "3nwsAdtkaVZ0"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PARTE 1 | Conjunto de Dados"
      ],
      "metadata": {
        "id": "IYmjAmCXaWCS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lWDJjBjiaGYg"
      },
      "outputs": [],
      "source": [
        "# 1. Carregar Dados do Kaggle\n",
        "def carregarDados(caminhoData: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Carrega e unifica os arquivos CSV do dataset de HRV via 'uuid'.\n",
        "    \"\"\"\n",
        "\n",
        "    dataframesBrutos = {}\n",
        "    try:\n",
        "        arquivosCsv = [f for f in os.listdir(caminhoData) if f.endswith('.csv')]\n",
        "        for arquivo in arquivosCsv:\n",
        "            nomeChave = arquivo.replace('.csv', '')\n",
        "            dataframesBrutos[nomeChave] = pd.read_csv(os.path.join(caminhoData, arquivo))\n",
        "\n",
        "        listaChaves = list(dataframesBrutos.keys())\n",
        "        dfUnificado = dataframesBrutos[listaChaves[0]]\n",
        "        for chave in listaChaves[1:]:\n",
        "            dfUnificado = pd.merge(dfUnificado, dataframesBrutos[chave], on='uuid', how='inner')\n",
        "\n",
        "        print(f\"Dataset carregado! E unificado:\\n    {dfUnificado.shape}\")\n",
        "        return dfUnificado\n",
        "    except Exception as e:\n",
        "        print(f\"Erro no carregamento: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "\n",
        "# 2. Seleção e Filtragem dos Dados\n",
        "def selecionarPreditoresETarget(dfEntrada: pd.DataFrame):\n",
        "    \"\"\"\n",
        "    Isola os preditores, remove classes intermediárias e elimina variáveis\n",
        "    com multicolinearidade extrema (correlação > 0.95).\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Filtragem: Focar nos extremos (No Stress vs Time Pressure)\n",
        "    # Removemos 'interruption' para limpar a fronteira de decisão e\n",
        "    # realizar uma classificação binária, apenas\n",
        "    dfLimpo = dfEntrada[dfEntrada['condition'] != 'interruption'].copy()\n",
        "    dfLimpo = dfLimpo.reset_index(drop=True)\n",
        "\n",
        "    # 2. Mapeamento Binário\n",
        "    mapeamentoClasses = {'no stress': 0, 'time pressure': 1}\n",
        "    y = dfLimpo['condition'].map(mapeamentoClasses).values\n",
        "\n",
        "    # 3. Identificação Automática de Preditores Numéricos\n",
        "    # Removemos colunas não-preditoras e o próprio alvo\n",
        "    colunasExcluir = ['uuid', 'datasetId', 'condition', 'target']\n",
        "    xBruto = dfLimpo.drop(columns=[c for c in colunasExcluir if c in dfLimpo.columns])\n",
        "    xBruto = xBruto.select_dtypes(include=[np.number]) # Garante apenas números\n",
        "\n",
        "    # 4. Filtro de Multicolinearidade (Estratégia Inteligente)\n",
        "    # Calculamos a matriz de correlação absoluta\n",
        "    matrizCorr = xBruto.corr().abs()\n",
        "\n",
        "    # Selecionamos o triângulo superior da matriz para identificar pares\n",
        "    superior = matrizCorr.where(np.triu(np.ones(matrizCorr.shape), k=1).astype(bool))\n",
        "\n",
        "    # Identificamos colunas com correlação acima de 0.95\n",
        "    colunasParaRemover = [coluna for coluna in superior.columns if any(superior[coluna] > 0.95)]\n",
        "\n",
        "    x = xBruto.drop(columns=colunasParaRemover)\n",
        "\n",
        "    print(f\"Filtragem concluída.\\n  Preditores finais: {x.shape[1]} (Removidas {len(colunasParaRemover)} redundantes).\")\n",
        "\n",
        "    return x, y\n",
        "\n",
        "# 2.1 Equilíbrio de Amostras (Opcional)\n",
        "def aplicarSubamostragem(xDados, yAlvo):\n",
        "    \"\"\"\n",
        "    Realiza o Undersampling aleatório da classe majoritária para equilibrar o dataset.\n",
        "    Retorna X e Y balanceados (proporção 50/50).\n",
        "    \"\"\"\n",
        "\n",
        "    # Identificamos os índices de cada classe\n",
        "    indicesClasse0 = np.where(yAlvo == 0)[0]\n",
        "    indicesClasse1 = np.where(yAlvo == 1)[0]\n",
        "\n",
        "    # Determinamos o tamanho da menor classe (geralmente Estresse)\n",
        "    n_minoria = len(indicesClasse1)\n",
        "\n",
        "    # Sorteamos aleatoriamente a mesma quantidade na classe majoritária\n",
        "    np.random.seed(27) # Para reprodutibilidade\n",
        "    indicesClasse0_Reduzidos = np.random.choice(indicesClasse0, n_minoria, replace=False)\n",
        "\n",
        "    # Combinamos os índices e extraímos os dados\n",
        "    indicesFinais = np.concatenate([indicesClasse0_Reduzidos, indicesClasse1])\n",
        "    np.random.shuffle(indicesFinais) # Mistura os dados\n",
        "\n",
        "    xBalanceado = xDados.iloc[indicesFinais] if isinstance(xDados, pd.DataFrame) else xDados[indicesFinais]\n",
        "    yBalanceado = yAlvo[indicesFinais]\n",
        "\n",
        "    print(f\"Subamostragem concluída: {len(yBalanceado)} amostras totais (50/50).\")\n",
        "\n",
        "    return xBalanceado, yBalanceado\n",
        "\n",
        "\n",
        "# 3. Divisão dos Conjuntos de Dados\n",
        "def dividirDados(xDados, yAlvo, proporcaoTeste=0.2):\n",
        "    \"\"\"\n",
        "    Apenas separa os dados em conjuntos de treino e teste de forma estratificada.\n",
        "    \"\"\"\n",
        "\n",
        "    xTreino, xTeste, yTreino, yTeste = train_test_split(\n",
        "        xDados, yAlvo, test_size=proporcaoTeste, random_state=42, stratify=yAlvo\n",
        "    )\n",
        "    print(f\"Divisão dos conjuntos concluída (Teste: {proporcaoTeste*100}%).\")\n",
        "    return xTreino, xTeste, yTreino, yTeste\n",
        "\n",
        "\n",
        "# 4. Transformação e normalização dos dados\n",
        "def aplicarTransformacoes(xTreino, xTeste):\n",
        "    \"\"\"\n",
        "    Aplica transformações para aproximar a distribuição normal e padroniza as escalas.\n",
        "    Utiliza Yeo-Johnson para corrigir assimetria e StandardScaler para Z-score.\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Transformação de Potência (Para aproximar da normalidade multivariada)\n",
        "    # O método Yeo-Johnson é ideal para corrigir a assimetria (skewness) das features de HRV!!\n",
        "    powerTrans = PowerTransformer(method='yeo-johnson')\n",
        "\n",
        "    # 2. Padronização (Média 0, Variância 1)\n",
        "    scaler = StandardScaler()\n",
        "\n",
        "    # Aplicamos o pipeline de transformação\n",
        "    # Nota: fit() apenas no treino para evitar vazamento de informação!\n",
        "    xTreinoTrans = powerTrans.fit_transform(xTreino)\n",
        "    xTreinoFinal = scaler.fit_transform(xTreinoTrans)\n",
        "\n",
        "    xTesteTrans = powerTrans.transform(xTeste)\n",
        "    xTesteFinal = scaler.transform(xTesteTrans)\n",
        "\n",
        "    print(\"Transformação Yeo-Johnson e padronização z-score aplicadas.\")\n",
        "    return xTreinoFinal, xTesteFinal"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# >> Pipeline de Execução\n",
        "\n",
        "# 1. Download e definição de caminhos\n",
        "path = kagglehub.dataset_download(\"vinayakshanawad/heart-rate-prediction-to-monitor-stress-level\")\n",
        "caminhoDados = os.path.join(path, 'Train Data', 'Train Data Zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z68UYvRzkdUo",
        "outputId": "075e2222-2f19-4492-c0fa-b0b508fc610a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (0.4.0).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/vinayakshanawad/heart-rate-prediction-to-monitor-stress-level?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 140M/140M [00:00<00:00, 154MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Ingestão e Unificação\n",
        "dfHrv = carregarDados(caminhoDados)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ip4qLcyflZEz",
        "outputId": "1ec1cf86-031f-4fd1-ac06-831b8a95f1e8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset carregado! E unificado:\n",
            "    (369289, 37)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if dfHrv is not None:\n",
        "    # 3. Seleção de Features e Mapeamento do Target (Binário)\n",
        "    # Aqui a função retorna os dados brutos ainda, apenas selecionados\n",
        "    xBruto, yAlvo = selecionarPreditoresETarget(dfHrv)\n",
        "\n",
        "    # 3.1 Aplicação da Subamostragem\n",
        "    xBalanceado, yBalanceado = aplicarSubamostragem(xBruto, yAlvo)\n",
        "\n",
        "    # 4. Divisão do Conjunto de Dados (Estratificada)\n",
        "    # Fundamental dividir ANTES de qualquer transformação para evitar Data Leakage!!!\n",
        "    xTreinoBruto, xTesteBruto, yTreino, yTeste = dividirDados(xBalanceado, yBalanceado, proporcaoTeste=0.2)\n",
        "\n",
        "    # 5. Transformação (Normalidade via Yeo-Johnson + Padronização Z-score)\n",
        "    # Agora aplicamos a matemática para atender às premissas do LDA\n",
        "    xTreino, xTeste = aplicarTransformacoes(xTreinoBruto, xTesteBruto)\n",
        "\n",
        "    print(\"\\nPipeline concluído com sucesso!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMuR3F3ygSOy",
        "outputId": "21a34277-73ce-4f42-9ff2-31180d3146be"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtragem concluída.\n",
            "  Preditores finais: 23 (Removidas 11 redundantes).\n",
            "Subamostragem concluída: 128114 amostras totais (50/50).\n",
            "Divisão dos conjuntos concluída (Teste: 20.0%).\n",
            "Transformação Yeo-Johnson e padronização z-score aplicadas.\n",
            "\n",
            "Pipeline concluído com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PARTE 2 | Regressão Logística"
      ],
      "metadata": {
        "id": "fzKZkKT7eqXY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MeuClassificadorLogistico:\n",
        "    \"\"\"\n",
        "    Implementação manual de Regressão Logística Binária.\n",
        "    Baseada no método de Máxima Verossimilhança e Gradiente Descendente.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, taxaAprendizado=0.1, iteracoes=5000):\n",
        "        self.taxaAprendizado = taxaAprendizado\n",
        "        self.iteracoes = iteracoes\n",
        "        self.weights = None  # Coeficientes Beta (incluindo intercepto)\n",
        "\n",
        "    def _sigmoid(self, z):\n",
        "        \"\"\"Função logística descrita nos slides: 1 / (1 + e^-z)\"\"\"\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "\n",
        "    def treinarModelo(self, xTreino, yTreino):\n",
        "        \"\"\"\n",
        "        Encontra os melhores coeficientes Beta minimizando a Log-Loss\n",
        "        (equivalente a maximizar a Verossimilhança).\n",
        "        \"\"\"\n",
        "        nAmostras, nPreditores = xTreino.shape\n",
        "\n",
        "        # Adiciona uma coluna de 1s para o Intercepto (Beta 0)\n",
        "        X = np.hstack([np.ones((nAmostras, 1)), xTreino])\n",
        "\n",
        "        # Inicializa pesos com zero\n",
        "        self.weights = np.zeros(nPreditores + 1)\n",
        "\n",
        "        # Gradiente Descendente\n",
        "        for _ in range(self.iteracoes):\n",
        "            # Modelo linear: z = beta0 + beta1*X1 + ...\n",
        "            modelo_linear = np.dot(X, self.weights)\n",
        "            # Predição probabilística (p(X))\n",
        "            previsoes = self._sigmoid(modelo_linear)\n",
        "\n",
        "            # Cálculo do erro e do gradiente (derivada da verossimilhança)\n",
        "            erro = previsoes - yTreino\n",
        "            gradiente = np.dot(X.T, erro) / nAmostras\n",
        "\n",
        "            # Atualização dos pesos: beta = beta - learning_rate * gradiente\n",
        "            self.weights -= self.taxaAprendizado * gradiente\n",
        "\n",
        "        print(f\"Treino Logístico concluído.\\n  Betas: {self.weights[:3]}...\")\n",
        "\n",
        "    def predizerProbabilidade(self, xTeste):\n",
        "        \"\"\"Retorna a probabilidade P(Y=1|X)\"\"\"\n",
        "        X = np.hstack([np.ones((xTeste.shape[0], 1)), xTeste])\n",
        "        return self._sigmoid(np.dot(X, self.weights))\n",
        "\n",
        "    def predizer(self, xTeste, threshold=0.5):\n",
        "        \"\"\"Classifica como 1 se p(X) > 0.5, senão 0\"\"\"\n",
        "        probabilidades = self.predizerProbabilidade(xTeste)\n",
        "        return np.array([1 if p >= threshold else 0 for p in probabilidades])"
      ],
      "metadata": {
        "id": "QSm94zAMetuG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Instanciar o modelo manual\n",
        "modeloLogistico = MeuClassificadorLogistico()\n",
        "\n",
        "# 2. Treinar com os dados transformados\n",
        "modeloLogistico.treinarModelo(xTreino, yTreino)\n",
        "\n",
        "# 3. Realizar as predições no conjunto de treino e teste\n",
        "yPreditoTreino = modeloLogistico.predizer(xTreino)\n",
        "yPreditoTeste = modeloLogistico.predizer(xTeste)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmLJV3qImq_f",
        "outputId": "619996b5-1195-42ba-aca2-292edb4a0824"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treino Logístico concluído.\n",
            "  Betas: [ 0.02999352  0.14667867 -1.27874175]...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EXTRA | Avaliação de Desempenho"
      ],
      "metadata": {
        "id": "YEV0vFCy87y8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calcularMetricas(yReal, yPrevisto):\n",
        "    \"\"\"\n",
        "    Calcula métricas de desempenho para classificação binária e exibe\n",
        "    um relatório estruturado no console.\n",
        "    \"\"\"\n",
        "\n",
        "    # Garante que os dados sejam arrays do numpy para as operações lógicas\n",
        "    yReal = np.array(yReal)\n",
        "    yPrevisto = np.array(yPrevisto)\n",
        "\n",
        "    # 1. Cálculos de Base (Matriz de Confusão)\n",
        "    tp = np.sum((yReal == 1) & (yPrevisto == 1))\n",
        "    tn = np.sum((yReal == 0) & (yPrevisto == 0))\n",
        "    fp = np.sum((yReal == 0) & (yPrevisto == 1))\n",
        "    fn = np.sum((yReal == 1) & (yPrevisto == 0))\n",
        "\n",
        "    # 2. Cálculo das Métricas Derivadas\n",
        "    acuracia = (tp + tn) / (tp + tn + fp + fn)\n",
        "\n",
        "    # Sensibilidade (Recall): Capacidade de detectar a classe 1 (Estresse)\n",
        "    sensibilidade = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "\n",
        "    # Especificidade: Capacidade de detectar a classe 0 (Calma)\n",
        "    especificidade = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "\n",
        "    # Precisão: Quando o modelo diz que é estresse, qual a chance de ser verdade?\n",
        "    precisao = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "\n",
        "    # F1-Score: Média harmônica entre precisão e sensibilidade\n",
        "    f1 = 2 * (precisao * sensibilidade) / (precisao + sensibilidade) if (precisao + sensibilidade) > 0 else 0\n",
        "\n",
        "    # 3. Prints Organizados e Estruturados)\n",
        "    print(\"Relatório de Desempenho\")\n",
        "    print(\"=\"*45)\n",
        "\n",
        "    print(f\"{'Métrica':<25} | {'Valor':<15}\")\n",
        "    print(\"-\" * 45)\n",
        "    print(f\"{'Acurácia Global':<25} | {acuracia:.2%}\")\n",
        "    print(f\"{'Sensibilidade (Recall)':<25} | {sensibilidade:.2%}\")\n",
        "    print(f\"{'Especificidade':<25} | {especificidade:.2%}\")\n",
        "    print(f\"{'Precisão':<25} | {precisao:.2%}\")\n",
        "    print(f\"{'F1-Score':<25} | {f1:.4f}\")\n",
        "\n",
        "    print(\"\\n\\n\")\n",
        "    print(\"Matriz de Confusão\")\n",
        "    print(\"-\" * 45)\n",
        "    print(f\"{'':>18} | {'Previsto: 0':<12} | {'Previsto: 1':<12}\")\n",
        "    print(f\"{'Real: 0 (Calma)':>18} | {tn:<12} | {fp:<12}\")\n",
        "    print(f\"{'Real: 1 (Estresse)':>18} | {fn:<12} | {tp:<12}\")\n",
        "    print(\"=\"*45 + \"\\n\")\n",
        "\n",
        "    matrizConfusao = np.array([[tn, fp], [fn, tp]])\n",
        "    return acuracia, matrizConfusao"
      ],
      "metadata": {
        "id": "bWpSc7wqkoSo"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Calcular métricas finais no teste\n",
        "print(\"Treino\")\n",
        "acuraciaGeralTreino, matrizConfusaoTreino = calcularMetricas(yTreino, yPreditoTreino)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EL9hlsWx4zYG",
        "outputId": "9587bfb7-957e-4987-83e8-5073434a8272"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treino\n",
            "Relatório de Desempenho\n",
            "=============================================\n",
            "Métrica                   | Valor          \n",
            "---------------------------------------------\n",
            "Acurácia Global           | 75.09%\n",
            "Sensibilidade (Recall)    | 76.84%\n",
            "Especificidade            | 73.35%\n",
            "Precisão                  | 74.25%\n",
            "F1-Score                  | 0.7552\n",
            "\n",
            "\n",
            "\n",
            "Matriz de Confusão\n",
            "---------------------------------------------\n",
            "                   | Previsto: 0  | Previsto: 1 \n",
            "   Real: 0 (Calma) | 37590        | 13655       \n",
            "Real: 1 (Estresse) | 11871        | 39375       \n",
            "=============================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Calcular métricas finais no teste\n",
        "print(\"Teste\")\n",
        "acuraciaGeralTeste, matrizConfusaoTeste = calcularMetricas(yTeste, yPreditoTeste)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fh0IwXwxIqEP",
        "outputId": "6588c0fe-a296-4684-9ddf-618ffa32200d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teste\n",
            "Relatório de Desempenho\n",
            "=============================================\n",
            "Métrica                   | Valor          \n",
            "---------------------------------------------\n",
            "Acurácia Global           | 75.28%\n",
            "Sensibilidade (Recall)    | 76.86%\n",
            "Especificidade            | 73.70%\n",
            "Precisão                  | 74.50%\n",
            "F1-Score                  | 0.7566\n",
            "\n",
            "\n",
            "\n",
            "Matriz de Confusão\n",
            "---------------------------------------------\n",
            "                   | Previsto: 0  | Previsto: 1 \n",
            "   Real: 0 (Calma) | 9442         | 3370        \n",
            "Real: 1 (Estresse) | 2965         | 9846        \n",
            "=============================================\n",
            "\n"
          ]
        }
      ]
    }
  ]
}