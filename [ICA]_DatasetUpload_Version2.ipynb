{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Etapa 1 | Carregamento, Pré-Processamento Inicial e Divisão dos Dados"
      ],
      "metadata": {
        "id": "R7mWTYBcWg6f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mo6GCJceWa9j"
      },
      "outputs": [],
      "source": [
        "# ETAPA 1.0 | Bibliotecas necessárias\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import kagglehub\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ETAPA 1.1 | Carregar dados do Kaggle\n",
        "\n",
        "def carregarDados(caminhoData: str) -> pd.DataFrame | None:\n",
        "    \"\"\"\n",
        "    Carrega e unifica os arquivos CSV do Kaggle dataset\n",
        "    ('time_domain', 'heart_rate_non_linear', 'frequency_domain').\n",
        "    \"\"\"\n",
        "\n",
        "    dataframes = {}\n",
        "\n",
        "    try:\n",
        "        csvFiles = [f for f in os.listdir(caminhoData) if f.endswith('.csv')]\n",
        "\n",
        "        if not csvFiles:\n",
        "            print(\"ERRO: Nenhum arquivo CSV encontrado.\")\n",
        "            return None\n",
        "\n",
        "        for fileName in csvFiles:\n",
        "            fullPath = os.path.join(caminhoData, fileName)\n",
        "            dfTemp = pd.read_csv(fullPath)\n",
        "\n",
        "            keyName = fileName.split('.csv')[0]\n",
        "            dataframes[keyName] = dfTemp\n",
        "            print(f\"✅ Carregado: {keyName} - {dfTemp.shape}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao carregar: {e}\")\n",
        "        return None\n",
        "\n",
        "    # Tentando identificar automaticamente quais são time / nonlinear / freq\n",
        "    possiveisChaves = list(dataframes.keys())\n",
        "\n",
        "    def buscarChave(texto):\n",
        "        for key in possiveisChaves:\n",
        "            if texto in key.lower():\n",
        "                return key\n",
        "        return None\n",
        "\n",
        "    chaveTime = buscarChave('time')\n",
        "    chaveNonLinear = buscarChave('non')\n",
        "    chaveFreq = buscarChave('frequency')\n",
        "\n",
        "    if not all([chaveTime, chaveNonLinear, chaveFreq]):\n",
        "        print(\"ERRO: Arquivos esperados não encontrados corretamente.\")\n",
        "        print(\"Arquivos encontrados:\", possiveisChaves)\n",
        "        return None\n",
        "\n",
        "    dfMerged = pd.merge(\n",
        "        dataframes[chaveTime],\n",
        "        dataframes[chaveNonLinear],\n",
        "        on='uuid',\n",
        "        how='inner'\n",
        "    )\n",
        "\n",
        "    dfFinal = pd.merge(\n",
        "        dfMerged,\n",
        "        dataframes[chaveFreq],\n",
        "        on='uuid',\n",
        "        how='inner'\n",
        "    )\n",
        "\n",
        "    print(f\"\\n✅ Dataset unificado com sucesso: {dfFinal.shape}\")\n",
        "\n",
        "    return dfFinal\n"
      ],
      "metadata": {
        "id": "xWsMGnfBWqII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ETAPA 1.2 | Transformação inicial dos dados\n",
        "\n",
        "def transformarDados(df: pd.DataFrame, colunaAlvo: str = 'HR'):\n",
        "    \"\"\"\n",
        "    Separa variáveis preditoras (X) e alvo (Y),\n",
        "    remove colunas irrelevantes e aplica One-Hot Encoding em 'condition'.\n",
        "    \"\"\"\n",
        "\n",
        "    if df is None:\n",
        "        print(\"ERRO: DataFrame vazio.\")\n",
        "        return None, None\n",
        "\n",
        "    # Colunas que não agregam valor (apenas identificadores)\n",
        "    colunasParaRemover = ['uuid', 'datasetId']\n",
        "\n",
        "    # Variável alvo (formato coluna para álgebra linear)\n",
        "    Y = df[colunaAlvo].values.reshape(-1, 1)\n",
        "\n",
        "    # Variáveis preditoras (remove alvo + ids)\n",
        "    X = df.drop(columns=[colunaAlvo] + colunasParaRemover, errors='ignore').copy()\n",
        "\n",
        "    # One-Hot Encoding para variável categórica 'condition'\n",
        "    # drop_first=True evita multicolinearidade perfeita\n",
        "    if 'condition' in X.columns:\n",
        "        X = pd.get_dummies(X, columns=['condition'], drop_first=True)\n",
        "\n",
        "    return X, Y"
      ],
      "metadata": {
        "id": "DpxV-3LWWs8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ETAPA 1.3 | Separação em treino e teste\n",
        "\n",
        "def dividirTreinoTeste(X, Y, tamanhoTeste=0.2, estadoAleatorio=27):\n",
        "    \"\"\"\n",
        "    Divide os dados em conjunto de treinamento e teste.\n",
        "    \"\"\"\n",
        "\n",
        "    # Separação usando proporção definida (ex: 80% treino / 20% teste)\n",
        "    XTrain, XTest, YTrain, YTest = train_test_split(\n",
        "        X, Y, test_size=tamanhoTeste, random_state=estadoAleatorio\n",
        "    )\n",
        "\n",
        "    print(f\"\\n✅ Divisão do Conjunto de Dados: CONCLUÍDA!\")\n",
        "    print(f\"   Treino: {XTrain.shape}\")\n",
        "    print(f\"   Teste: {XTest.shape}\")\n",
        "\n",
        "    return XTrain, XTest, YTrain, YTest"
      ],
      "metadata": {
        "id": "mibzPRR0Wu87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ETAPA 1.4 | Pré-processamento dos preditores\n",
        "'''\n",
        "def preProcessarFeatures(XTrainRaw, XTestRaw):\n",
        "    \"\"\"\n",
        "    Aplica transformação logarítmica, imputação e padronização (scaling).\n",
        "    O ajuste é feito APENAS no conjunto de treino!\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Transformação Log (reduzir assimetria)\n",
        "    XTrainLog = np.log1p(XTrainRaw)\n",
        "    XTestLog  = np.log1p(XTestRaw)\n",
        "\n",
        "    # 2. Imputação (usa apenas estatísticas do TREINO)\n",
        "    imputer = SimpleImputer(strategy='median')\n",
        "    imputer.fit(XTrainLog)\n",
        "\n",
        "    XTrainLog = pd.DataFrame(\n",
        "        imputer.transform(XTrainLog),\n",
        "        columns=XTrainRaw.columns,\n",
        "        index=XTrainRaw.index\n",
        "    )\n",
        "\n",
        "    XTestLog = pd.DataFrame(\n",
        "        imputer.transform(XTestLog),\n",
        "        columns=XTestRaw.columns,\n",
        "        index=XTestRaw.index\n",
        "    )\n",
        "\n",
        "    # 3. Padronização\n",
        "    scaler = StandardScaler()\n",
        "    XTrainScaled = scaler.fit_transform(XTrainLog)\n",
        "    XTestScaled  = scaler.transform(XTestLog)\n",
        "\n",
        "    # Recriar DataFrames\n",
        "    XTrain = pd.DataFrame(XTrainScaled, columns=XTrainLog.columns, index=XTrainLog.index)\n",
        "    XTest  = pd.DataFrame(XTestScaled, columns=XTestLog.columns, index=XTestLog.index)\n",
        "\n",
        "    return XTrain, XTest, scaler\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "# com Yeo-Johnson!!!\n",
        "def preProcessarFeatures(XTrainRaw, XTestRaw):\n",
        "    \"\"\"\n",
        "    Aplica transformação Yeo-Johnson e padronização (scaling).\n",
        "    O ajuste é feito APENAS no conjunto de treino!\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Transformação Yeo-Johnson\n",
        "    # Diferente do log, aceita valores negativos!!!\n",
        "    # Reduz assimetria e deixa as features mais próximas de uma distribuição normal\n",
        "    pt = PowerTransformer(method='yeo-johnson')\n",
        "\n",
        "    # Ajusta APENAS no treinamento (evita vazamento de dados)\n",
        "    XTrainTransf = pt.fit_transform(XTrainRaw)\n",
        "    # Aplica a MESMA transformação no conjunto de teste\n",
        "    XTestTransf  = pt.transform(XTestRaw)\n",
        "\n",
        "    # Reconstrói como DataFrame (mantém colunas e índices)\n",
        "    XTrainTransf = pd.DataFrame(XTrainTransf, columns=XTrainRaw.columns, index=XTrainRaw.index\n",
        "    )\n",
        "\n",
        "    XTestTransf = pd.DataFrame(XTestTransf, columns=XTestRaw.columns, index=XTestRaw.index\n",
        "    )\n",
        "\n",
        "    # 2. Padronização\n",
        "    # Necessária para modelos com regularização\n",
        "    scaler = StandardScaler()\n",
        "\n",
        "    # Ajusta no treino e aplica no teste\n",
        "    XTrainScaled = scaler.fit_transform(XTrainTransf)\n",
        "    XTestScaled  = scaler.transform(XTestTransf)\n",
        "\n",
        "    # Reconstrói DataFrames finais\n",
        "    XTrain = pd.DataFrame(XTrainScaled, columns=XTrainTransf.columns, index=XTrainTransf.index)\n",
        "    XTest  = pd.DataFrame(XTestScaled, columns=XTestTransf.columns, index=XTestTransf.index)\n",
        "\n",
        "    return XTrain, XTest, scaler\n"
      ],
      "metadata": {
        "id": "k7Pd8eytWw0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EXECUÇÃO DA ETAPA 1 | Pipeline Completo\n",
        "\n",
        "# 1.\n",
        "path = kagglehub.dataset_download(\"vinayakshanawad/heart-rate-prediction-to-monitor-stress-level\")\n",
        "caminhoDados = os.path.join(path, 'Train Data', 'Train Data Zip')\n",
        "\n",
        "df = carregarDados(caminhoDados)\n",
        "\n",
        "# 2.\n",
        "X, Y = transformarDados(df, colunaAlvo='HR')\n",
        "\n",
        "# 3.\n",
        "XTrainRaw, XTestRaw, YTrain, YTest = dividirTreinoTeste(\n",
        "    X, Y,\n",
        "    tamanhoTeste=0.2,\n",
        "    estadoAleatorio=27\n",
        ")\n",
        "\n",
        "# 4.\n",
        "XTrain, XTest, scaler = preProcessarFeatures(XTrainRaw, XTestRaw)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mu5WSfnlW0Zx",
        "outputId": "2759c9f8-6c59-4a90-d476-234e83a38514"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/vinayakshanawad/heart-rate-prediction-to-monitor-stress-level?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 140M/140M [00:02<00:00, 65.1MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Carregado: time_domain_features_train - (369289, 20)\n",
            "✅ Carregado: frequency_domain_features_train - (369289, 12)\n",
            "✅ Carregado: heart_rate_non_linear_features_train - (369289, 7)\n",
            "\n",
            "✅ Dataset unificado com sucesso: (369289, 37)\n",
            "\n",
            "✅ Divisão do Conjunto de Dados: CONCLUÍDA!\n",
            "   Treino: (295431, 35)\n",
            "   Teste: (73858, 35)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pandas/core/internals/blocks.py:393: RuntimeWarning: invalid value encountered in log1p\n",
            "  result = func(self.values, **kwargs)\n"
          ]
        }
      ]
    }
  ]
}