{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PARTE 0 | Importes Necessários"
      ],
      "metadata": {
        "id": "V_LLfWXdaM9z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, PowerTransformer"
      ],
      "metadata": {
        "id": "3nwsAdtkaVZ0"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PARTE 1 | Conjunto de Dados"
      ],
      "metadata": {
        "id": "IYmjAmCXaWCS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lWDJjBjiaGYg"
      },
      "outputs": [],
      "source": [
        "# 1. Carregar Dados do Kaggle\n",
        "def carregarDados(caminhoData: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Carrega e unifica os arquivos CSV do dataset de HRV via 'uuid'.\n",
        "    \"\"\"\n",
        "\n",
        "    dataframesBrutos = {}\n",
        "    try:\n",
        "        arquivosCsv = [f for f in os.listdir(caminhoData) if f.endswith('.csv')]\n",
        "        for arquivo in arquivosCsv:\n",
        "            nomeChave = arquivo.replace('.csv', '')\n",
        "            dataframesBrutos[nomeChave] = pd.read_csv(os.path.join(caminhoData, arquivo))\n",
        "\n",
        "        listaChaves = list(dataframesBrutos.keys())\n",
        "        dfUnificado = dataframesBrutos[listaChaves[0]]\n",
        "        for chave in listaChaves[1:]:\n",
        "            dfUnificado = pd.merge(dfUnificado, dataframesBrutos[chave], on='uuid', how='inner')\n",
        "\n",
        "        print(f\"Dataset carregado! E unificado:\\n    {dfUnificado.shape}\")\n",
        "        return dfUnificado\n",
        "    except Exception as e:\n",
        "        print(f\"Erro no carregamento: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "\n",
        "# 2. Seleção e Filtragem dos Dados\n",
        "def selecionarPreditoresETarget(dfEntrada: pd.DataFrame):\n",
        "    \"\"\"\n",
        "    Isola os preditores, remove classes intermediárias e elimina variáveis\n",
        "    com multicolinearidade extrema (correlação > 0.95).\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Filtragem: Focar nos extremos (No Stress vs Time Pressure)\n",
        "    # Removemos 'interruption' para limpar a fronteira de decisão e\n",
        "    # realizar uma classificação binária, apenas\n",
        "    dfLimpo = dfEntrada[dfEntrada['condition'] != 'interruption'].copy()\n",
        "    dfLimpo = dfLimpo.reset_index(drop=True)\n",
        "\n",
        "    # 2. Mapeamento Binário\n",
        "    mapeamentoClasses = {'no stress': 0, 'time pressure': 1}\n",
        "    y = dfLimpo['condition'].map(mapeamentoClasses).values\n",
        "\n",
        "    # 3. Identificação Automática de Preditores Numéricos\n",
        "    # Removemos colunas não-preditoras e o próprio alvo\n",
        "    colunasExcluir = ['uuid', 'datasetId', 'condition', 'target']\n",
        "    xBruto = dfLimpo.drop(columns=[c for c in colunasExcluir if c in dfLimpo.columns])\n",
        "    xBruto = xBruto.select_dtypes(include=[np.number]) # Garante apenas números\n",
        "\n",
        "    # 4. Filtro de Multicolinearidade (Estratégia Inteligente)\n",
        "    # Calculamos a matriz de correlação absoluta\n",
        "    matrizCorr = xBruto.corr().abs()\n",
        "\n",
        "    # Selecionamos o triângulo superior da matriz para identificar pares\n",
        "    superior = matrizCorr.where(np.triu(np.ones(matrizCorr.shape), k=1).astype(bool))\n",
        "\n",
        "    # Identificamos colunas com correlação acima de 0.95\n",
        "    colunasParaRemover = [coluna for coluna in superior.columns if any(superior[coluna] > 0.95)]\n",
        "\n",
        "    x = xBruto.drop(columns=colunasParaRemover)\n",
        "\n",
        "    print(f\"Filtragem concluída.\\n  Preditores finais: {x.shape[1]} (Removidas {len(colunasParaRemover)} redundantes).\")\n",
        "\n",
        "    return x, y\n",
        "\n",
        "# 2.1 Equilíbrio de Amostras (Opcional)\n",
        "def aplicarSubamostragem(xDados, yAlvo):\n",
        "    \"\"\"\n",
        "    Realiza o Undersampling aleatório da classe majoritária para equilibrar o dataset.\n",
        "    Retorna X e Y balanceados (proporção 50/50).\n",
        "    \"\"\"\n",
        "\n",
        "    # Identificamos os índices de cada classe\n",
        "    indicesClasse0 = np.where(yAlvo == 0)[0]\n",
        "    indicesClasse1 = np.where(yAlvo == 1)[0]\n",
        "\n",
        "    # Determinamos o tamanho da menor classe (geralmente Estresse)\n",
        "    n_minoria = len(indicesClasse1)\n",
        "\n",
        "    # Sorteamos aleatoriamente a mesma quantidade na classe majoritária\n",
        "    np.random.seed(27) # Para reprodutibilidade\n",
        "    indicesClasse0_Reduzidos = np.random.choice(indicesClasse0, n_minoria, replace=False)\n",
        "\n",
        "    # Combinamos os índices e extraímos os dados\n",
        "    indicesFinais = np.concatenate([indicesClasse0_Reduzidos, indicesClasse1])\n",
        "    np.random.shuffle(indicesFinais) # Mistura os dados\n",
        "\n",
        "    xBalanceado = xDados.iloc[indicesFinais] if isinstance(xDados, pd.DataFrame) else xDados[indicesFinais]\n",
        "    yBalanceado = yAlvo[indicesFinais]\n",
        "\n",
        "    print(f\"Subamostragem concluída: {len(yBalanceado)} amostras totais (50/50).\")\n",
        "\n",
        "    return xBalanceado, yBalanceado\n",
        "\n",
        "\n",
        "# 3. Divisão dos Conjuntos de Dados\n",
        "def dividirDados(xDados, yAlvo, proporcaoTeste=0.2):\n",
        "    \"\"\"\n",
        "    Apenas separa os dados em conjuntos de treino e teste de forma estratificada.\n",
        "    \"\"\"\n",
        "\n",
        "    xTreino, xTeste, yTreino, yTeste = train_test_split(\n",
        "        xDados, yAlvo, test_size=proporcaoTeste, random_state=42, stratify=yAlvo\n",
        "    )\n",
        "    print(f\"Divisão dos conjuntos concluída (Teste: {proporcaoTeste*100}%).\")\n",
        "    return xTreino, xTeste, yTreino, yTeste\n",
        "\n",
        "\n",
        "# 4. Transformação e normalização dos dados\n",
        "def aplicarTransformacoes(xTreino, xTeste):\n",
        "    \"\"\"\n",
        "    Aplica transformações para aproximar a distribuição normal e padroniza as escalas.\n",
        "    Utiliza Yeo-Johnson para corrigir assimetria e StandardScaler para Z-score.\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Transformação de Potência (Para aproximar da normalidade multivariada)\n",
        "    # O método Yeo-Johnson é ideal para corrigir a assimetria (skewness) das features de HRV!!\n",
        "    powerTrans = PowerTransformer(method='yeo-johnson')\n",
        "\n",
        "    # 2. Padronização (Média 0, Variância 1)\n",
        "    scaler = StandardScaler()\n",
        "\n",
        "    # Aplicamos o pipeline de transformação\n",
        "    # Nota: fit() apenas no treino para evitar vazamento de informação!\n",
        "    xTreinoTrans = powerTrans.fit_transform(xTreino)\n",
        "    xTreinoFinal = scaler.fit_transform(xTreinoTrans)\n",
        "\n",
        "    xTesteTrans = powerTrans.transform(xTeste)\n",
        "    xTesteFinal = scaler.transform(xTesteTrans)\n",
        "\n",
        "    print(\"Transformação Yeo-Johnson e padronização z-score aplicadas.\")\n",
        "    return xTreinoFinal, xTesteFinal"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# >> Pipeline de Execução\n",
        "\n",
        "# 1. Download e definição de caminhos\n",
        "path = kagglehub.dataset_download(\"vinayakshanawad/heart-rate-prediction-to-monitor-stress-level\")\n",
        "caminhoDados = os.path.join(path, 'Train Data', 'Train Data Zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z68UYvRzkdUo",
        "outputId": "987a2f54-717a-42ba-ec2f-167a82ec121e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'heart-rate-prediction-to-monitor-stress-level' dataset.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Ingestão e Unificação\n",
        "dfHrv = carregarDados(caminhoDados)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ip4qLcyflZEz",
        "outputId": "66d1bd18-673a-4eac-b29a-c2e6aa3a8d34"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset carregado! E unificado:\n",
            "    (369289, 37)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy.stats as stats\n",
        "\n",
        "def verificarNormalidade(xOriginal, xTransformado, feature_idx=0):\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "    # Antes da transformação\n",
        "    sns.histplot(xOriginal.iloc[:, feature_idx], kde=True, ax=axes[0], color='red')\n",
        "    axes[0].set_title(f\"Original: {xOriginal.columns[feature_idx]}\")\n",
        "\n",
        "    # Depois da transformação ( Yeo-Johnson + Scaler)\n",
        "    sns.histplot(xTransformado[:, feature_idx], kde=True, ax=axes[1], color='green')\n",
        "    axes[1].set_title(f\"Após Yeo-Johnson: {xOriginal.columns[feature_idx]}\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Exemplo de uso:\n",
        "# verificarNormalidade(xTreinoBruto, xTreino, feature_idx=2)"
      ],
      "metadata": {
        "id": "bXKF0ANJgJJ5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if dfHrv is not None:\n",
        "    # 3. Seleção de Features e Mapeamento do Target (Binário)\n",
        "    # Aqui a função retorna os dados brutos ainda, apenas selecionados\n",
        "    xBruto, yAlvo = selecionarPreditoresETarget(dfHrv)\n",
        "\n",
        "    # 3.1 Aplicação da Subamostragem\n",
        "    xBalanceado, yBalanceado = aplicarSubamostragem(xBruto, yAlvo)\n",
        "\n",
        "    # 4. Divisão do Conjunto de Dados (Estratificada)\n",
        "    # Fundamental dividir ANTES de qualquer transformação para evitar Data Leakage!!!\n",
        "    xTreinoBruto, xTesteBruto, yTreino, yTeste = dividirDados(xBalanceado, yBalanceado, proporcaoTeste=0.2)\n",
        "\n",
        "    # 5. Transformação (Normalidade via Yeo-Johnson + Padronização Z-score)\n",
        "    # Agora aplicamos a matemática para atender às premissas do LDA\n",
        "    xTreino, xTeste = aplicarTransformacoes(xTreinoBruto, xTesteBruto)\n",
        "\n",
        "    print(\"\\nPipeline concluído com sucesso!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMuR3F3ygSOy",
        "outputId": "cd91b4a5-b2be-4cfc-a4aa-a1e9f75d796a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtragem concluída.\n",
            "  Preditores finais: 23 (Removidas 11 redundantes).\n",
            "Subamostragem concluída: 128114 amostras totais (50/50).\n",
            "Divisão dos conjuntos concluída (Teste: 20.0%).\n",
            "Transformação Yeo-Johnson e padronização z-score aplicadas.\n",
            "\n",
            "Pipeline concluído com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PARTE 2 | Análise Discriminante Linear"
      ],
      "metadata": {
        "id": "fzKZkKT7eqXY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MeuClassificadorLDA:\n",
        "    \"\"\"\n",
        "    Implementação manual da Análise Discriminante Linear (LDA).\n",
        "    O modelo busca encontrar um vetor que maximize a separação entre classes\n",
        "    utilizando a função discriminante linear:\n",
        "\n",
        "    δ_k(x) = xᵀ Σ⁻¹ μ_k - 1/2 μ_kᵀ Σ⁻¹ μ_k + log(π_k)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.mediasClasses = {}               # Vetores mu_k | Vetor de médias da classe k\n",
        "        self.probabilidadesPriori = {}        # Pesos pi_k | Probabilidade a priori da classe k\n",
        "        self.matrizCovarianciaComum = None    # Matriz Sigma | Matriz de covariância comum\n",
        "        self.inversaCovariancia = None        # Sigma^-1 | Inversa da matriz de covariância comum\n",
        "        self.classes = None\n",
        "\n",
        "    def treinarModelo(self, xTreino, yTreino):\n",
        "        \"\"\"\n",
        "        Estima os parâmetros estatísticos necessários para a fronteira de decisão.\n",
        "        \"\"\"\n",
        "        nAmostras, nPreditores = xTreino.shape\n",
        "        self.classes = np.unique(yTreino)\n",
        "\n",
        "        # Inicialização da estrutura da matriz de covariância comum\n",
        "        self.matrizCovarianciaComum = np.zeros((nPreditores, nPreditores))\n",
        "\n",
        "        for classe in self.classes:\n",
        "            xClasse = xTreino[yTreino == classe]\n",
        "\n",
        "            # 1. Cálculo do centroide (média) da classe no espaço n-dimensional\n",
        "            self.mediasClasses[classe] = np.mean(xClasse, axis=0)\n",
        "\n",
        "            # 2. Probabilidade a Priori (pi_k) balanceada\n",
        "            # Aqui, em vez de xClasse.shape[0] / nAmostras, usamos pesos iguais, pois\n",
        "            # neutralizamos o viés da prevalência da classe majoritária no dataset,\n",
        "            # forçando o discriminante a focar exclusivamente na variância fisiológica.\n",
        "            self.probabilidadesPriori[classe] = 1.0 / len(self.classes)\n",
        "\n",
        "            # 3. Acúmulo da dispersão intra-classe para compor a matriz Sigma unificada\n",
        "            desvios = xClasse - self.mediasClasses[classe]\n",
        "            self.matrizCovarianciaComum += np.dot(desvios.T, desvios)\n",
        "\n",
        "        # Cálculo da média ponderada da covariância (estimativa não enviesada)\n",
        "        self.matrizCovarianciaComum /= (nAmostras - len(self.classes))\n",
        "\n",
        "        # 4. Cálculo da Pseudoinversa (Moore-Penrose) para contornar a singularidade\n",
        "        # causada por preditores altamente correlacionados (multicolinearidade).\n",
        "        self.inversaCovariancia = np.linalg.pinv(self.matrizCovarianciaComum)\n",
        "\n",
        "        print(f\"Treino concluído com prioris uniformes: {self.probabilidadesPriori}\")\n",
        "\n",
        "    def calcularDiscriminante(self, xAmostra):\n",
        "        \"\"\"\n",
        "        Calcula o score de projeção para cada classe conforme a geometria do LDA.\n",
        "        \"\"\"\n",
        "        scores = {}\n",
        "        invSigma = self.inversaCovariancia\n",
        "\n",
        "        for classe in self.classes:\n",
        "            muK = self.mediasClasses[classe]\n",
        "            piK = self.probabilidadesPriori[classe]\n",
        "\n",
        "            # Produto escalar ponderado pela inversa da covariância\n",
        "            termoLinear = np.dot(np.dot(xAmostra, invSigma), muK)\n",
        "\n",
        "            # Penalização baseada na distância ao centroide da classe\n",
        "            termoQuadratico = -0.5 * np.dot(np.dot(muK.T, invSigma), muK)\n",
        "\n",
        "            # Logaritmo da probabilidade a priori (constante nesta versão balanceada)\n",
        "            termoLogPrior = np.log(piK)\n",
        "\n",
        "            scores[classe] = termoLinear + termoQuadratico + termoLogPrior\n",
        "\n",
        "        return scores\n",
        "\n",
        "    def predizer(self, xTeste):\n",
        "        \"\"\"\n",
        "        Aplica o critério de máxima verossimilhança para rotular os novos dados.\n",
        "        \"\"\"\n",
        "        previsoes = []\n",
        "        for amostra in xTeste:\n",
        "            scores = self.calcularDiscriminante(amostra)\n",
        "            # Decisão baseada na classe que maximiza a função delta\n",
        "            classeEscolhida = max(scores, key=scores.get)\n",
        "            previsoes.append(classeEscolhida)\n",
        "\n",
        "        return np.array(previsoes)"
      ],
      "metadata": {
        "id": "QSm94zAMetuG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Instanciar o modelo manual\n",
        "modeloLda = MeuClassificadorLDA()\n",
        "\n",
        "# 2. Treinar com os dados transformados\n",
        "modeloLda.treinarModelo(xTreino, yTreino)\n",
        "\n",
        "# 3. Realizar as predições no conjunto de treino e teste\n",
        "yPreditoTreino = modeloLda.predizer(xTreino)\n",
        "yPreditoTeste = modeloLda.predizer(xTeste)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmLJV3qImq_f",
        "outputId": "472976df-e547-4947-bb50-ff61dbebb555"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treino concluído com prioris uniformes: {np.int64(0): 0.5, np.int64(1): 0.5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EXTRA | Avaliação de Desempenho"
      ],
      "metadata": {
        "id": "YEV0vFCy87y8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calcularMetricas(yReal, yPrevisto):\n",
        "    \"\"\"\n",
        "    Calcula métricas de desempenho para classificação binária e exibe\n",
        "    um relatório estruturado no console.\n",
        "    \"\"\"\n",
        "    # 1. Cálculos de Base (Matriz de Confusão)\n",
        "    tp = np.sum((yReal == 1) & (yPrevisto == 1))\n",
        "    tn = np.sum((yReal == 0) & (yPrevisto == 0))\n",
        "    fp = np.sum((yReal == 0) & (yPrevisto == 1))\n",
        "    fn = np.sum((yReal == 1) & (yPrevisto == 0))\n",
        "\n",
        "    # 2. Cálculo das Métricas Derivadas\n",
        "    acuracia = (tp + tn) / (tp + tn + fp + fn)\n",
        "\n",
        "    # Sensibilidade (Recall): Capacidade de detectar a classe 1 (Estresse)\n",
        "    sensibilidade = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "\n",
        "    # Especificidade: Capacidade de detectar a classe 0 (Calma)\n",
        "    especificidade = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "\n",
        "    # Precisão: Quando o modelo diz que é estresse, qual a chance de ser verdade?\n",
        "    precisao = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "\n",
        "    # F1-Score: Média harmônica entre precisão e sensibilidade\n",
        "    f1 = 2 * (precisao * sensibilidade) / (precisao + sensibilidade) if (precisao + sensibilidade) > 0 else 0\n",
        "\n",
        "    # 3. Prints Organizados e Estruturados)\n",
        "    print(\"Relatório de Desempenho da LDA\")\n",
        "    print(\"=\"*45)\n",
        "\n",
        "    print(f\"{'Métrica':<25} | {'Valor':<15}\")\n",
        "    print(\"-\" * 45)\n",
        "    print(f\"{'Acurácia Global':<25} | {acuracia:.2%}\")\n",
        "    print(f\"{'Sensibilidade (Recall)':<25} | {sensibilidade:.2%}\")\n",
        "    print(f\"{'Especificidade':<25} | {especificidade:.2%}\")\n",
        "    print(f\"{'Precisão':<25} | {precisao:.2%}\")\n",
        "    print(f\"{'F1-Score':<25} | {f1:.4f}\")\n",
        "\n",
        "    print(\"\\n\\n\")\n",
        "    print(\"Matriz de Confusão\")\n",
        "    print(\"-\" * 45)\n",
        "    print(f\"{'':>18} | {'Previsto: 0':<12} | {'Previsto: 1':<12}\")\n",
        "    print(f\"{'Real: 0 (Calma)':>18} | {tn:<12} | {fp:<12}\")\n",
        "    print(f\"{'Real: 1 (Estresse)':>18} | {fn:<12} | {tp:<12}\")\n",
        "    print(\"=\"*45 + \"\\n\")\n",
        "\n",
        "    matrizConfusao = np.array([[tn, fp], [fn, tp]])\n",
        "    return acuracia, matrizConfusao"
      ],
      "metadata": {
        "id": "bWpSc7wqkoSo"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Calcular métricas finais no teste\n",
        "print(\"Treino\")\n",
        "acuraciaGeralTreino, matrizConfusaoTreino = calcularMetricas(yTreino, yPreditoTreino)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EL9hlsWx4zYG",
        "outputId": "8de302ea-1f83-4435-abaa-5b799f707c8b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treino\n",
            "Relatório de Desempenho da LDA\n",
            "=============================================\n",
            "Métrica                   | Valor          \n",
            "---------------------------------------------\n",
            "Acurácia Global           | 75.44%\n",
            "Sensibilidade (Recall)    | 77.51%\n",
            "Especificidade            | 73.37%\n",
            "Precisão                  | 74.43%\n",
            "F1-Score                  | 0.7594\n",
            "\n",
            "\n",
            "\n",
            "Matriz de Confusão\n",
            "---------------------------------------------\n",
            "                   | Previsto: 0  | Previsto: 1 \n",
            "   Real: 0 (Calma) | 37599        | 13646       \n",
            "Real: 1 (Estresse) | 11523        | 39723       \n",
            "=============================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Calcular métricas finais no teste\n",
        "print(\"Teste\")\n",
        "acuraciaGeralTeste, matrizConfusaoTeste = calcularMetricas(yTeste, yPreditoTeste)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fh0IwXwxIqEP",
        "outputId": "ecbe9ca8-2755-4b04-d281-97ffb5cb4206"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teste\n",
            "Relatório de Desempenho da LDA\n",
            "=============================================\n",
            "Métrica                   | Valor          \n",
            "---------------------------------------------\n",
            "Acurácia Global           | 75.81%\n",
            "Sensibilidade (Recall)    | 77.86%\n",
            "Especificidade            | 73.77%\n",
            "Precisão                  | 74.80%\n",
            "F1-Score                  | 0.7630\n",
            "\n",
            "\n",
            "\n",
            "Matriz de Confusão\n",
            "---------------------------------------------\n",
            "                   | Previsto: 0  | Previsto: 1 \n",
            "   Real: 0 (Calma) | 9451         | 3361        \n",
            "Real: 1 (Estresse) | 2836         | 9975        \n",
            "=============================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PARTE 3 | Análise Discriminante Quadrática"
      ],
      "metadata": {
        "id": "ERkvcjX99AwR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MeuClassificadorQDA:\n",
        "    \"\"\"\n",
        "    Implementação manual da Análise Discriminante Quadrática (QDA).\n",
        "    A fronteira de decisão é quadrática, permitindo que cada classe tenha sua\n",
        "    própria estrutura de covariância. A equação do discriminante é:\n",
        "\n",
        "    δ_k(x) = -1/2 log|Σ_k| - 1/2 (x - μ_k)ᵀ Σ_k⁻¹ (x - μ_k) + log(π_k)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.mediasClasses = {}             # Vetores mu_k | Vetor de médias da classe k\n",
        "        self.inversasCovariancia = {}       # Matrizes Sigma_k^-1 | Inversas das matrizes de covariância por classe\n",
        "        self.determinantesLog = {}          # log|Sigma_k| | Logaritmo do determinante da matriz de covariância por classe\n",
        "        self.probabilidadesPriori = {}      # Pesos pi_k | Probabilidade a priori da classe k\n",
        "        self.classes = None\n",
        "\n",
        "    def treinarModelo(self, xTreino, yTreino):\n",
        "        \"\"\"\n",
        "        Estima médias e matrizes de covariância específicas para cada classe.\n",
        "        \"\"\"\n",
        "        self.classes = np.unique(yTreino)\n",
        "\n",
        "        for classe in self.classes:\n",
        "            xClasse = xTreino[yTreino == classe]\n",
        "\n",
        "            # 1. Média da classe\n",
        "            self.mediasClasses[classe] = np.mean(xClasse, axis=0)\n",
        "\n",
        "            # 2. Probabilidade a Priori (50/50 para balanceamento)\n",
        "            self.probabilidadesPriori[classe] = 1.0 / len(self.classes)\n",
        "\n",
        "            # 3. Matriz de Covariância Específica (Σ_k)\n",
        "            # Calculamos a covariância apenas com os dados desta classe\n",
        "            matrizCov = np.cov(xClasse, rowvar=False)\n",
        "\n",
        "            # 4. Estabilização e Inversão\n",
        "            # Usamos a Pseudoinversa e calculamos o Log do Determinante para a fórmula\n",
        "            self.inversasCovariancia[classe] = np.linalg.pinv(matrizCov)\n",
        "\n",
        "            # Determinante usando SVD para estabilidade numérica em matrizes grandes\n",
        "            signo, logdet = np.linalg.slogdet(matrizCov)\n",
        "            self.determinantesLog[classe] = logdet\n",
        "\n",
        "        print(f\"Treino do QDA concluído para as classes: {self.classes}\")\n",
        "\n",
        "    def calcularDiscriminante(self, xAmostra):\n",
        "        \"\"\"\n",
        "        Calcula o score quadrático δ_k(x).\n",
        "        \"\"\"\n",
        "        scores = {}\n",
        "        for classe in self.classes:\n",
        "            mu_k = self.mediasClasses[classe]\n",
        "            invSigma_k = self.inversasCovariancia[classe]\n",
        "            logDet_k = self.determinantesLog[classe]\n",
        "            pi_k = self.probabilidadesPriori[classe]\n",
        "\n",
        "            # Cálculo da Distância de Mahalanobis: (x - μ)ᵀ Σ⁻¹ (x - μ)\n",
        "            diff = xAmostra - mu_k\n",
        "            distanciaMahalanobis = np.dot(np.dot(diff.T, invSigma_k), diff)\n",
        "\n",
        "            # Equação completa do discriminante quadrático\n",
        "            # O termo -0.5 * logDet_k é o que diferencia o QDA do LDA\n",
        "            score = -0.5 * logDet_k - 0.5 * distanciaMahalanobis + np.log(pi_k)\n",
        "\n",
        "            scores[classe] = score\n",
        "\n",
        "        return scores\n",
        "\n",
        "    def predizer(self, xTeste):\n",
        "        \"\"\"\n",
        "        Classifica as amostras com base no maior score quadrático.\n",
        "        \"\"\"\n",
        "        previsoes = [max(self.calcularDiscriminante(a), key=self.calcularDiscriminante(a).get) for a in xTeste]\n",
        "        return np.array(previsoes)"
      ],
      "metadata": {
        "id": "_vQcI-if9BQr"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Instanciar o modelo manual do QDA\n",
        "modeloQda = MeuClassificadorQDA()\n",
        "\n",
        "# 2. Treinar com os dados transformados\n",
        "modeloQda.treinarModelo(xTreino, yTreino)\n",
        "\n",
        "# 3. Realizar as predições no conjunto de treino e teste\n",
        "yPreditoQdaTreino = modeloQda.predizer(xTreino)\n",
        "yPreditoQdaTeste = modeloQda.predizer(xTeste)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Y-YefZu9k_7",
        "outputId": "1bcc98b8-3f78-49e2-996e-5bea5a69ca36"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treino do QDA concluído para as classes: [0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EXTRA | Avaliação de Desempenho"
      ],
      "metadata": {
        "id": "Qdbe68wGJMY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Calcular métricas finais no treino\n",
        "print(\"Treino\")\n",
        "acuraciaGeralTreino, matrizConfusaoTreino = calcularMetricas(yTreino, yPreditoQdaTreino)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgA7eH42Jssh",
        "outputId": "7fdd56d9-634b-4be7-aa3e-e36d3524a590"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treino\n",
            "Relatório de Desempenho da LDA\n",
            "=============================================\n",
            "Métrica                   | Valor          \n",
            "---------------------------------------------\n",
            "Acurácia Global           | 83.09%\n",
            "Sensibilidade (Recall)    | 85.93%\n",
            "Especificidade            | 80.25%\n",
            "Precisão                  | 81.31%\n",
            "F1-Score                  | 0.8356\n",
            "\n",
            "\n",
            "\n",
            "Matriz de Confusão\n",
            "---------------------------------------------\n",
            "                   | Previsto: 0  | Previsto: 1 \n",
            "   Real: 0 (Calma) | 41123        | 10122       \n",
            "Real: 1 (Estresse) | 7209         | 44037       \n",
            "=============================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Calcular métricas finais no teste\n",
        "print(\"Teste\")\n",
        "acuraciaGeralTeste, matrizConfusaoTeste = calcularMetricas(yTeste, yPreditoQdaTeste)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVby6nXq9nPa",
        "outputId": "465a025f-359d-42ff-bc02-8c7b12828ddc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teste\n",
            "Relatório de Desempenho da LDA\n",
            "=============================================\n",
            "Métrica                   | Valor          \n",
            "---------------------------------------------\n",
            "Acurácia Global           | 83.10%\n",
            "Sensibilidade (Recall)    | 85.72%\n",
            "Especificidade            | 80.49%\n",
            "Precisão                  | 81.46%\n",
            "F1-Score                  | 0.8353\n",
            "\n",
            "\n",
            "\n",
            "Matriz de Confusão\n",
            "---------------------------------------------\n",
            "                   | Previsto: 0  | Previsto: 1 \n",
            "   Real: 0 (Calma) | 10312        | 2500        \n",
            "Real: 1 (Estresse) | 1830         | 10981       \n",
            "=============================================\n",
            "\n"
          ]
        }
      ]
    }
  ]
}